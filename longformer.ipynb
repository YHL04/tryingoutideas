{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoHuka22YT9wn3uhVdWjd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YHL04/tryingoutideas/blob/main/longformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhsJm9Fziy48"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def _skew(x, direction, padding_value):\n",
        "  '''Convert diagonals into columns (or columns into diagonals depending on `direction`'''\n",
        "  x_padded = F.pad(x, direction, value=padding_value)\n",
        "  x_padded = x_padded.view(*x_padded.size()[:-2], x_padded.size(-1), x_padded.size(-2))\n",
        "  return x_padded\n",
        "\n",
        "\n",
        "def _chunk(x, w):\n",
        "  '''convert into overlapping chunkings. Chunk size = 2w, overlap size = w'''\n",
        "\n",
        "  # non-overlapping chunks of size = 2w\n",
        "  x = x.view(x.size(0), x.size(1) // (w * 2), w * 2, x.size(2))\n",
        "\n",
        "  # use `as_strided` to make the chunks overlap with an overlap size = w\n",
        "  chunk_size = list(x.size())\n",
        "  chunk_size[1] = chunk_size[1] * 2 - 1\n",
        "\n",
        "  chunk_stride = list(x.stride())\n",
        "  chunk_stride[1] = chunk_stride[1] // 2\n",
        "\n",
        "  return x.as_strided(size=chunk_size, stride=chunk_stride)\n",
        "\n",
        "\n",
        "def sliding_chunks_matmul_qk(q, k, w):\n",
        "  bsz, seqlen, num_heads, head_dim = q.size()\n",
        "\n",
        "  chunks_count = seqlen // w - 1\n",
        "\n",
        "  q = q.transpose(1, 2).reshape(bsz * num_heads, seqlen, head_dim)\n",
        "  k = k.transpose(1, 2).reshape(bsz * num_heads, seqlen, head_dim)\n",
        "\n",
        "  chunk_q = _chunk(q, w)\n",
        "  chunk_k = _chunk(k, w)\n",
        "\n",
        "  chunk_attn = torch.einsum('bcxd,bcyd->bcxy', (chunk_q, chunk_k))  # multiply\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.arange(8).reshape(2, 4)\n",
        "y = torch.arange(12).reshape(3, 4) + 1\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "\n",
        "print(torch.matmul(x, y.transpose(0, 1)))\n",
        "print(torch.einsum('xd,yd->xy', (x, y)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OjGxRpVBEXb",
        "outputId": "d9575ceb-fbdd-499e-b7f5-a3c668be82e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "tensor([[ 20,  44,  68],\n",
            "        [ 60, 148, 236]])\n",
            "tensor([[ 20,  44,  68],\n",
            "        [ 60, 148, 236]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.arange(16).reshape(4, 4)\n",
        "padded = torch.nn.functional.pad(x, (0, 0, 0, 1))\n",
        "print(x)\n",
        "print(padded)\n",
        "print(padded.view(padded.size(-1), padded.size(-2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NJEPj0KCqHh",
        "outputId": "f7e28d14-539d-4e4d-9f71-9332ea05bbaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [ 0,  0,  0,  0]])\n",
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15,  0,  0,  0,  0]])\n"
          ]
        }
      ]
    }
  ]
}